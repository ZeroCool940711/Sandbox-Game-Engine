<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   
      <title>Chapter&nbsp;23.&nbsp;Post Processing</title>
      <link rel="stylesheet" type="text/css" href="../css/bigworld.css">
      <meta name="generator" content="DocBook XSL Stylesheets V1.76.1">
      <link rel="home" href="index.html" title="Client Programming Guide">
      <link rel="up" href="index.html" title="Client Programming Guide">
      <link rel="prev" href="ch22.html" title="Chapter&nbsp;22.&nbsp;3D Engine (Moo)">
      <link rel="next" href="ch24.html" title="Chapter&nbsp;24.&nbsp;Job System">
   </head>
   <body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF">
      <div id="bigworld-header"><img src="http://try.bigworldtech.com/bigworld/image.php?img=bigworld_logo.gif&amp;svn=$HeadURL: http://patchsvn/svn/evaluation/official/IndiePackage/2.1/current/bigworld/doc/html/client_programming_guide/ch23.html $" alt="bw logo"></div>
      <div id="content">
         <div class="navheader">
            <table width="95%" align="center" summary="Navigation header">
               <tr>
                  <th colspan="3" align="center">Chapter&nbsp;23.&nbsp;Post Processing</th>
               </tr>
               <tr>
                  <td width="20%" align="left"><a accesskey="p" href="ch22.html">Prev</a>&nbsp;
                  </td>
                  <th width="55%" align="center">&nbsp;</th>
                  <td width="20%" align="right">&nbsp;<a accesskey="n" href="ch24.html">Next</a></td>
               </tr>
            </table>
            <hr class="navheaderline">
         </div>
         <div class="chapter" title="Chapter&nbsp;23.&nbsp;Post Processing">
            <div class="titlepage">
               <div>
                  <div>
                     <h2 class="title"><a name="xref_Post_Processing"></a>Chapter&nbsp;23.&nbsp;Post Processing
                     </h2>
                  </div>
               </div>
            </div>
            <div class="toc">
               <p><b>Table of Contents</b></p>
               <dl>
                  <dt><span class="section"><a href="ch23.html#xref_Post_Processing_Pipeline">23.1. Pipeline Overview</a></span></dt>
                  <dt><span class="section"><a href="ch23.html#d0e12111">23.2. Creating a Custom Post-Processing Effect</a></span></dt>
                  <dd>
                     <dl>
                        <dt><span class="section"><a href="ch23.html#d0e12120">23.2.1. Creating the Custom Pixel Shader</a></span></dt>
                        <dt><span class="section"><a href="ch23.html#d0e12143">23.2.2. Previewing the Results</a></span></dt>
                        <dt><span class="section"><a href="ch23.html#d0e12164">23.2.3. Writing a Custom Pixel Shader for Previewing the Results</a></span></dt>
                        <dt><span class="section"><a href="ch23.html#d0e12178">23.2.4. Authoring a Post-Processing Effect in Python</a></span></dt>
                     </dl>
                  </dd>
                  <dt><span class="section"><a href="ch23.html#d0e12266">23.3. Render Targets</a></span></dt>
                  <dt><span class="section"><a href="ch23.html#d0e12299">23.4. Performance</a></span></dt>
                  <dd>
                     <dl>
                        <dt><span class="section"><a href="ch23.html#d0e12304">23.4.1. Measuring the Time Spent on the GPU</a></span></dt>
                        <dt><span class="section"><a href="ch23.html#d0e12317">23.4.2. Background Loading</a></span></dt>
                     </dl>
                  </dd>
               </dl>
            </div>
            <p>Post-processing effects are used extensively in all modern games, and
                 have many applications - from HDR tone-mapping and colour-correction to
                 cartoon effects, the possibilities are almost limitless.
            </p>
            <p>BigWorld Technology has support for complete user customisation of the
                 post-processing chain, for artists via a built-in editing tool, and for
                 programmers by offering full control over every parameter in python and
                 drop-in shaders in the way of DirectX/HLSL effect files.
            </p>
            <p>However before you jump into creating your own new swanky effect, it
                 pays to think about it. Effects should play nicely together, they should
                 reuse render targets where possible, and you need to monitor
                 performance.
            </p>
            <div class="section" title="23.1.&nbsp;Pipeline Overview">
               <div class="titlepage">
                  <div>
                     <div>
                        <h2 class="title" style="clear: both"><a name="xref_Post_Processing_Pipeline"></a>23.1.&nbsp;Pipeline Overview
                        </h2>
                     </div>
                  </div>
               </div>
               <p>After the opaque scene, translucencies and lens effects, and before
                      the GUI is drawn, the <em class="emphasis">PostProcessing::Manager</em> draws its current chain. A
                      <em class="emphasis">Chain</em> contains a list of effects that
                      draw in order. Internally each <em class="emphasis">Effect</em>
                      contains a list of Phases that draw in order. A <em class="emphasis">Phase</em> usually draws a full-screen quad to the
                      screen using an effect file, although other transfer meshes are
                      available.
               </p>
               <p>There are three parts to the implementation of post-processing. The
                      core is written in C++, in the
                      <em class="emphasis">bigworld/src/lib/post_processing</em> library. All of the
                      features there are exposed to python via the <em class="emphasis">_PostProcessing</em> module.
               </p>
               <p>In Python, the <em class="emphasis">PostProcessing</em>
                      module exists in
                      <em class="emphasis">bigworld/res/scripts/client/PostProcessing</em> and
                      imports all of the methods from <em class="emphasis">_PostProcessing</em>. This allows you to override, or
                      wrap, any of the C++ methods. Therefore all python calls should be to the
                      <em class="emphasis">PostProcessing</em>, not <em class="emphasis">_PostProcessing</em>.
               </p>
               <p>By default, the <em class="emphasis">PostProcessing</em>
                      module registers 3 graphics settings. If the user selects high/medium/low,
                      an appropriate post-processing chain is loaded. These are found in
                      <em class="emphasis">bigworld/res/system/post_processing/chains/</em> and are
                      "High Graphics Setting.ppchain", "Medium Graphics Setting.ppchain" and
                      "Low Graphics Setting.ppchain". Therefore it is easy for developers to
                      redefine the default post-processing chains by creating new chains in
                      World Editor and saving over the top of these files.
               </p>
               <p>In general it is expected that a game will use a combination of the
                      default post-processing chain files, dynamically mixed in with gameplay
                      related effects. In order to achieve this, follow the examples in the
                      <em class="emphasis">PostProcessing</em> module. Additionally, take
                      a look at the Python API for <em class="emphasis">PyMaterial</em>,
                      as it will demonstrate how you can smoothly fade in/out your dynamic
                      post-processing effects.
               </p>
               <p>Finally in World Editor, the Post-Processing tab is a full-featured
                      editor and preview tool for chains. It loads and saves .ppchain files.
                      Please see the <a href="../..//content_creation.chm" class="olink">Content Creation Manual</a> and the
                      <a href="../content_tools_reference_guide/index.html" class="olink">Content Tools Reference Guide</a> for further
                      information.
               </p>
            </div>
            <div class="section" title="23.2.&nbsp;Creating a Custom Post-Processing Effect">
               <div class="titlepage">
                  <div>
                     <div>
                        <h2 class="title" style="clear: both"><a name="d0e12111"></a>23.2.&nbsp;Creating a Custom Post-Processing Effect
                        </h2>
                     </div>
                  </div>
               </div>
               <p>While BigWorld comes with a basic set of post-processing shaders,
                      phases and effects, more likely than not you will find yourself needing to
                      implement an effect that is unique to your game.
               </p>
               <p>For this example, we will be creating a post-process that will
                      invert all the colours on the screen.
               </p>
               <p>We will author a post-processing effect that can be added as part of
                      the client's overall post-processing chain, and we will write a custom
                      shader that performs the actual colour inversion.
               </p>
               <div class="section" title="23.2.1.&nbsp;Creating the Custom Pixel Shader">
                  <div class="titlepage">
                     <div>
                        <div>
                           <h3 class="title"><a name="d0e12120"></a>23.2.1.&nbsp;Creating the Custom Pixel Shader
                           </h3>
                        </div>
                     </div>
                  </div>
                  <p>So how are we going to get the GPU to invert all the colours on
                           the screen?
                  </p>
                  <p>Because the BigWorld client supports drop-in DirectX Effect files
                           (.fx), this step is relatively easy. All we need to do is author a .fx
                           file that takes an input texture, inverts the colour, and outputs that
                           value.
                  </p><pre class="programlisting">float4 ps_invert(PS_INPUT input) : COLOR0
{
    float4 map = tex2D(inputTextureSampler, input.tc0);
    float4 invMap = float4(1,1,1,1) - map;
    invMap.w = 1;
    return invMap;
}</pre><p>OK, so that was the easy bit. This pixel shader assumes a
                           couple of things, namely that the vertex shader is passing through a set
                           of texture coordinates, that there is a sampler reading the correct
                           texture map, and that there is a PS_INPUT structure defined.
                  </p>
                  <p>Luckily all of this has been taken care of, via the effect include
                           file post_processing.fxh
                           (bigworld/res/shaders/post_processing/post_processing.fxh)
                  </p>
                  <p>The complete effect utilising this pixel shader is quite
                           straightforward, and looks something like this:
                  </p><pre class="programlisting">#include "post_processing.fxh"

DECLARE_EDITABLE_TEXTURE( inputTexture, inputSampler, CLAMP, CLAMP, LINEAR, "Input texture/render target" )

float4 ps_invert(PS_INPUT input) : COLOR0
{
    float4 map = tex2D(inputSampler, input.tc0);
    float4 invMap = float4(1,1,1,1) - map;
    invMap.w = 1;
    return invMap;
}

STANDARD_PP_TECHNIQUE(compile vs_2_0 vs_pp_default(), compile ps_2_0 ps_invert())</pre><p>The shaders can also be edited in FX Composer by adding the
                           following:
                  </p><pre class="programlisting">#define FX_COMPOSER 1

#include "post_processing.fxh"

FX_COMPOSER_STANDARD_VARS

DECLARE_EDITABLE_TEXTURE( inputTexture, inputSampler, CLAMP, CLAMP, LINEAR, "Input texture/render target" )

float4 ps_invert(PS_INPUT input) : COLOR0
{
    float4 map = tex2D(inputSampler, input.tc0);
    float4 invMap = float4(1,1,1,1) - map;
    invMap.w = 1;
    return invMap;
}

STANDARD_PP_TECHNIQUE(compile vs_2_0 vs_pp_default(), compile ps_2_0 ps_invert())
STANDARD_FX_COMPOSER_TECHNIQUE(compile vs_2_0 vs_pp_default(), compile ps_2_0 ps_invert(), "RenderColorTarget0=inputTexture;")</pre><p>In the FX Composer settings, add the path to post_processing.fxh
                           and the other post processing headers to your include path. Comment out
                           #define FX_COMPOSER 1 to use the shader in the client or world
                           editor.
                  </p>
               </div>
               <div class="section" title="23.2.2.&nbsp;Previewing the Results">
                  <div class="titlepage">
                     <div>
                        <div>
                           <h3 class="title"><a name="d0e12143"></a>23.2.2.&nbsp;Previewing the Results
                           </h3>
                        </div>
                     </div>
                  </div>
                  <p>As the post-processing chain contains many phases, which often
                           write to intermediate, invisible render targets, it is often desirable
                           to see the intermediate results of a post-processing effect or chain.
                           There are two methods available for this purpose, <em class="emphasis">PostProcessing.debug()</em> and World Editor's preview
                           feature.
                  </p>
                  <p>In the client, you can register a render target of arbitrary size
                           with the <em class="emphasis">_PostProcessing</em> module, and
                           have it record all intermediate steps. This render target can then be
                           viewed by displaying it in the GUI. A helper class, <em class="emphasis">ChainView</em>, is available in the <em class="emphasis">PostProcessing</em> module, this will display the
                           entire chain on-screen in real-time.
                  </p>
                  <p>In World Editor, there is a preview button in the post-processing
                           editor, this displays the intermediate results inside each of the phase
                           nodes in the editing graph.
                  </p>
               </div>
               <div class="section" title="23.2.3.&nbsp;Writing a Custom Pixel Shader for Previewing the Results">
                  <div class="titlepage">
                     <div>
                        <div>
                           <h3 class="title"><a name="d0e12164"></a>23.2.3.&nbsp;Writing a Custom Pixel Shader for Previewing the Results
                           </h3>
                        </div>
                     </div>
                  </div>
                  <p>Sometimes, this simple preview is not going to be suitable. By
                           default, the preview directly displays the output of each phase's pixel
                           shader. However, often the output of an intermediate step is written to
                           a floating-point render target that does not directly map to the visible
                           colour range, other times there is information encoded in specific ways
                           that are not directly viewable.
                  </p>
                  <p>Take for example a depth-of-field lens simulation. One possible
                           implementation might decode the depth buffer, and categorise the scene
                           into 7 separate areas, 3 levels of blur in front of the focal range,
                           in-focus and 3 levels after. This information may be written into a
                           single-component floating point render target and contain a value
                           between -3 and +3.
                  </p>
                  <p>When the output of a pixel shader is not directly viewable, you
                           can author another pixel shader that is used for the preview function.
                           To do this, you need to add a new technique to your effect. This
                           technique must be called "<em class="emphasis">Preview</em>", and
                           if available, will be used in lieu of the main technique when previewing
                           the post-processing chain. This technique should output the data such
                           that it will be viewable and make sense on an ordinary R8G8B8A8 render
                           target and when viewed on-screen.
                  </p>
                  <p>In the above example, you could write a preview technique that
                           displays 3 shades of red for blurred areas in front of the focal range,
                           full-green for all areas in focus, and 3 shades of blue for all areas
                           being blurred behind the focal range.
                  </p>
               </div>
               <div class="section" title="23.2.4.&nbsp;Authoring a Post-Processing Effect in Python">
                  <div class="titlepage">
                     <div>
                        <div>
                           <h3 class="title"><a name="d0e12178"></a>23.2.4.&nbsp;Authoring a Post-Processing Effect in Python
                           </h3>
                        </div>
                     </div>
                  </div>
                  <p>So now how do we get our new effect to manipulate the screen at
                           post-processing time? We have to author a <em class="emphasis">PostProcessing::Effect</em>. Most often, this will be
                           done via the post-processing editor in World Editor. World Editor saves
                           out .ppchain files, these contain chains of effects and phases, and can
                           simply be loaded up and set as the current post-processing chain.
                           However, it's also useful to know how to use the Python API, as you do
                           have access to the entire chain, and often you will want to tie in
                           post-processing effects directly to game logic. It also helps to
                           understand what is happening 'under-the-hood' when authoring chains in
                           the editor.
                  </p>
                  <p>For this example effect, we must write every pixel in the
                           backbuffer with the inverse of whatever colour is in the
                           backbuffer.
                  </p>
                  <p>PC hardware cannot read from the same texture that is being
                           written to, so we will need first to grab a copy of the back buffer, and
                           store it in another texture.
                  </p>
                  <p>This snippet of python code creates a <em class="emphasis">CopyBackBuffer</em> phase, creates a render target
                           that is the size of the back buffer, and hooks the two up.
                  </p><pre class="programlisting">import PostProcessing

phase1 = PostProcessing.CopyBackBuffer()
bbcRT = BigWorld.RenderTarget("backBufferCopy", 0, 0)
phase1.renderTarget = bbcRT</pre><p>In World Editor, we can simply drop a "BackBufferCopy" phase into
                           our effect and be done with it.
                  </p>
                  <p>Note in this case, we are creating a new render target, however
                           generally you want to share render targets between effects and phases,
                           especially full-screen ones like the one above. So instead of creating a
                           render target, we could instead use the <em class="emphasis">RenderTargets</em> module like this:
                  </p><pre class="programlisting">bbcRT = PostProcessing.RenderTargets.rt("backBufferCopy")
</pre><p>Now we have a copy of the back buffer that we can read in as
                           a texture, now is time to do our colour inversion pass
                  </p><pre class="programlisting">phase2 = PostProcessing.Phase()
phase2.material = BigWorld.Material("shaders/post_processing/colour_invert.fx")
phase2.material.inputTexture = phase1.renderTarget.texture
phase2.renderTarget = None
phase2.filterQuad = PostProcessing.TransferQuad()</pre><p>This code
                           sample creates a new phase, this time a generic <em class="emphasis">PyPhase</em> object. A <em class="emphasis">PyPhase</em> object has a <em class="emphasis">PyMaterial</em> and a <em class="emphasis">FilterQuad</em>. It uses these to write to a <em class="emphasis">RenderTarget</em>.
                  </p>
                  <p>We have created a new <em class="emphasis">PyMaterial</em>,
                           from "colour_invert.fx", the shader we authored earlier.
                  </p>
                  <p>The effect file uses a texture variable named "inputTexture".
                           Since we marked this variable in the effect as 'editable', it shows up
                           in the python dictionary for the material. Thus we can set it directly
                           to the texture held by the back buffer copy render target.
                  </p>
                  <p>We have set this phase's <em class="emphasis">renderTarget</em>
                           attribute to None. Specifically this means "don't set a render target",
                           in practice this means we want to write directly to the main scene's
                           back buffer, instead of an off-screen render target.
                  </p>
                  <p>Note that whenever we write to the back buffer, we change its
                           contents, and the next post-processing effect or phase must use a new
                           copy that contains these changes. The <em class="emphasis">BackBufferCopy</em> phase internally detects whether
                           or not the back buffer has been modified since the last copy was taken.
                           Therefore it is ok to use <em class="emphasis">BackBufferCopy</em> phases all the time, and there
                           will be no performance penalty if that phase is in fact not needed at
                           that time.
                  </p>
                  <p>Finally the phase uses a <em class="emphasis">FilterQuad</em> to draw with; these usually draw with
                           n sets of filter taps, in this case we just want to read a single pixel
                           from the source texture, for each pixel in the output render target. So
                           we have created a <em class="emphasis">PyTransferQuad</em>, which
                           has only a single sample point, and with no offsets. If we wanted to do
                           some texture filtering, we could have used a <em class="emphasis">PyFilterQuad</em> instead, and specified n sample
                           points - with each sample point representing (u-offset in texels,
                           v-offset in texels, weight, unused).
                  </p><pre class="programlisting">colourInvert = PostProcessing.Effect()
colourInvert.phases = [phase1, phase2]
colourInvert.name = "Invert Colours"
PostProcessing.chain([colourInvert])
</pre><p>This final code example wraps up our two phases into a single
                           <em class="emphasis">Effect</em>, and registers the Effect as the
                           post-processing chain. From here on in, the colours on the screen will
                           be inverted.
                  </p>
               </div>
            </div>
            <div class="section" title="23.3.&nbsp;Render Targets">
               <div class="titlepage">
                  <div>
                     <div>
                        <h2 class="title" style="clear: both"><a name="d0e12266"></a>23.3.&nbsp;Render Targets
                        </h2>
                     </div>
                  </div>
               </div>
               <p>One of the main sets of resources used by post-processing chains are
                      render targets. These tend to be multiples of the back buffer size, and
                      have different surface formats and uses. The BigWorld client exposes the
                      <em class="emphasis">PyRenderTarget</em> class which can be used to
                      create custom render targets on demand. Please see the <em class="emphasis">Python
                         Client API</em> for detailed instructions on how to use <em class="emphasis">PyRenderTarget</em>.
               </p>
               <p>Note that it is ok to create as many render targets as you like, as
                      the actual surface memory is only allocated when the render target is
                      first used for drawing into (via <em class="emphasis">RenderTarget.push</em>).
                      Therefore you can define render targets that are not actually used, with
                      negligible overhead. However for the render targets in use, the video
                      memory can quickly add up, so it pays to take care when designing your
                      post processing chains. The total memory used by any particular chain can
                      be viewed in the World Editor, or by calling the function
                      <em class="emphasis">PostProcessing.RenderTargets.reportMemoryUsage()</em>.
               </p>
               <p>In Python, the <em class="emphasis">PostProcessing</em>
                      module has its own <em class="emphasis">RenderTargets</em> module,
                      in
                      <em class="emphasis">bigworld/res/scripts/client/PostProcessing/RenderTargets</em>.
                      If you want to add more render targets for use by your post-processing
                      chains, then add them to the render target list here. Doing this is
                      necessary because this is where World Editor gets its list of available
                      post-processing render targets.
               </p>
            </div>
            <div class="section" title="23.4.&nbsp;Performance">
               <div class="titlepage">
                  <div>
                     <div>
                        <h2 class="title" style="clear: both"><a name="d0e12299"></a>23.4.&nbsp;Performance
                        </h2>
                     </div>
                  </div>
               </div>
               <p>There are two main performance metrics to be aware of when authoring
                      post-processing chains. These are: memory use (mainly by the render
                      targets); and the time spent in the GPU. Render targets and their
                      associated memory use are described in the previous chapter. As always,
                      PostProcessing resources created dynamically should be loaded in the
                      background thread, to avoid stalling the rendering thread.
               </p>
               <div class="section" title="23.4.1.&nbsp;Measuring the Time Spent on the GPU">
                  <div class="titlepage">
                     <div>
                        <div>
                           <h3 class="title"><a name="d0e12304"></a>23.4.1.&nbsp;Measuring the Time Spent on the GPU
                           </h3>
                        </div>
                     </div>
                  </div>
                  <p>Post-processing chains tend to have a low CPU cost - involving
                           simple iteration through effects and phases and simple geometry setup -
                           but a high GPU cost, with complex pixel shaders that perform full-screen
                           passes and many texture fetches per pixel. Therefore the main cost is
                           normally GPU bandwidth: fill-rate, and texture-fetch.
                  </p>
                  <p>The BigWorld client has a python API function,
                           <em class="emphasis">PostProcessing.profile(nIterations)</em>, which measures
                           the time taken by the GPU. The parameter
                           <em class="emphasis">nIterations</em> should usually be around 10 or so to
                           make sure an accurate value is measured. Since the main cost is
                           fill-rate and texture-fetch, this value depends on the resolution of the
                           screen, so it is necessary to profile on different GPUs and at different
                           resolutions. Note that World Editor also comes with a toolbar button on
                           the Post-Processing panel that also profiles the chain.
                  </p>
               </div>
               <div class="section" title="23.4.2.&nbsp;Background Loading">
                  <div class="titlepage">
                     <div>
                        <div>
                           <h3 class="title"><a name="d0e12317"></a>23.4.2.&nbsp;Background Loading
                           </h3>
                        </div>
                     </div>
                  </div>
                  <p>There is no direct support for background creation of <em class="emphasis">.ppchain</em> files, since the library uses many
                           <em class="emphasis">PyObject</em> pointers which can only be
                           created in the main thread. Instead, support for background loading of
                           .ppchain files can be achieved via the
                           <em class="emphasis">PostProcessing.prerequisites()</em> method. This
                           extracts the appropriate resources (mainly EffectMaterials) from the XML
                           file and returns a list of the required resources which can then be
                           passed directly to
                           <em class="emphasis">BigWorld.loadResourceListBG()</em>.
                  </p>
                  <p>For example:</p><pre class="programlisting">filename = "system/post_processing/chains/underwater.ppchain"
BigWorld.loadResourceListBG(PostProcessing.prerequisites(filename), onLoadBG)</pre><p>PostProcessing chains loaded via the SFX system are automatically
                           loaded in the background.
                  </p>
                  <p>Because gathering the PostProcessing prerequisites relies on the
                           .ppchain file data section already being loaded, it is recommended that
                           you <em class="emphasis">preload</em> all your .ppchain XML
                           files.
                  </p>
               </div>
            </div>
         </div>
         <div class="navfooter">
            <hr class="navheaderline">
            <table width="95%" align="center" summary="Navigation footer">
               <tr>
                  <td width="38%" align="left"><a accesskey="p" href="ch22.html">Prev</a>&nbsp;
                  </td>
                  <td width="20%" align="center">&nbsp;</td>
                  <td width="37%" align="right">&nbsp;<a accesskey="n" href="ch24.html">Next</a></td>
               </tr>
               <tr>
                  <td width="40%" align="left" valign="top">Chapter&nbsp;22.&nbsp;3D Engine (Moo)&nbsp;</td>
                  <td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td>
                  <td width="40%" align="right" valign="top">&nbsp;Chapter&nbsp;24.&nbsp;Job System</td>
               </tr>
               <tr>
                  <td colspan="3">Copyright 1999-2012 BigWorld Pty. Ltd. All rights reserved. Proprietary commercial in confidence.
                     		   
                  </td>
               </tr>
            </table>
         </div>
      </div>
   </body>
</html>